{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a5f23b64",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Requirement already satisfied: transformers in c:\\users\\laksh\\anaconda3\\lib\\site-packages (4.8.2)\n",
      "Requirement already satisfied: filelock in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from transformers) (3.0.12)\n",
      "Requirement already satisfied: huggingface-hub==0.0.12 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from transformers) (0.0.12)\n",
      "Requirement already satisfied: pyyaml in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: sacremoses in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from transformers) (0.0.45)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from transformers) (2021.4.4)\n",
      "Requirement already satisfied: tqdm>=4.27 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from transformers) (4.59.0)\n",
      "Requirement already satisfied: requests in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from transformers) (2.25.1)\n",
      "Requirement already satisfied: numpy>=1.17 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from transformers) (1.20.1)\n",
      "Requirement already satisfied: packaging in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from transformers) (20.9)\n",
      "Requirement already satisfied: typing-extensions in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from huggingface-hub==0.0.12->transformers) (3.7.4.3)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from packaging->transformers) (2.4.7)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from requests->transformers) (1.26.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from requests->transformers) (2020.12.5)\n",
      "Requirement already satisfied: chardet<5,>=3.0.2 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from requests->transformers) (4.0.0)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from requests->transformers) (2.10)\n",
      "Requirement already satisfied: click in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (7.1.2)\n",
      "Requirement already satisfied: six in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.15.0)\n",
      "Requirement already satisfied: joblib in c:\\users\\laksh\\anaconda3\\lib\\site-packages (from sacremoses->transformers) (1.0.1)\n",
      "Requirement already satisfied: sentencepiece in c:\\users\\laksh\\anaconda3\\lib\\site-packages (0.1.96)\n"
     ]
    }
   ],
   "source": [
    "!pip install transformers\n",
    "!pip install sentencepiece"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a03c29f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "import joblib\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "import transformers\n",
    "from transformers import AutoModel, BertTokenizerFast\n",
    "from transformers import pipeline\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bff4df00",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = AutoTokenizer.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')\n",
    "model = AutoModel.from_pretrained('sentence-transformers/bert-base-nli-mean-tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b9a1571",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "C:\\Users\\laksh\\anaconda3\\lib\\site-packages\\sklearn\\base.py:310: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.22.2.post1 when using version 0.24.1. This might lead to breaking code or invalid results. Use at your own risk.\n  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "neigh = joblib.load('filename.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e81157dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "# function to remove HTML tags\n",
    "def remove_html_tags(text):\n",
    "    return BeautifulSoup(text, 'html.parser').get_text()\n",
    "\n",
    "\n",
    "import unicodedata\n",
    "# function to remove accented characters\n",
    "def remove_accented_chars(text):\n",
    "    new_text = unicodedata.normalize('NFKD', text).encode('ascii', 'ignore').decode('utf-8', 'ignore')\n",
    "    return new_text\n",
    "# call function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "59b2c24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clean(incoming):\n",
    "  var = []\n",
    "  for sen in incoming:\n",
    "    sen = remove_html_tags(sen)\n",
    "    sen = remove_accented_chars(sen)\n",
    "    var.append(sen)\n",
    "\n",
    "  return var\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2d38e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Setting to use the 0th GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "## Setting to use the bart-large-cnn model for summarization\n",
    "#summarizer = pipeline(\"summarization\")\n",
    "\n",
    "## To use the t5-base model for summarization:\n",
    "summarizer = pipeline(\"summarization\", model=\"t5-base\", tokenizer=\"t5-base\", framework=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "309bc666",
   "metadata": {},
   "outputs": [],
   "source": [
    "  def listify(lis):\n",
    "    txt = []\n",
    "\n",
    "    for x in lis:\n",
    "      if len(x.split()) > 400:\n",
    "        txt.append(summarizer(x, max_length=100, min_length=5, do_sample=False)[0]['summary_text'])\n",
    "      \n",
    "      elif len(x.split()) > 200:\n",
    "        txt.append(summarizer(x, max_length=70, min_length=5, do_sample=False)[0]['summary_text'])\n",
    "      \n",
    "      elif len(x.split()) > 100:\n",
    "        txt.append(summarizer(x, max_length=60, min_length=5, do_sample=False)[0]['summary_text'])\n",
    "\n",
    "      elif len(x.split()) > 75:\n",
    "        txt.append(summarizer(x, max_length=50, min_length=5, do_sample=False)[0]['summary_text'])\n",
    "\n",
    "      else :\n",
    "        txt.append(summarizer(x, max_length=40, min_length=5, do_sample=False)[0]['summary_text'])\n",
    "    \n",
    "    return txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "640fcdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPreds(txt):\n",
    "  encoded_input = tokenizer(txt, padding=True, truncation=True, return_tensors='pt')\n",
    "\n",
    "  # Compute token embeddings\n",
    "  with torch.no_grad():\n",
    "      model_output = model(**encoded_input)\n",
    "  bert_embeddings = model_output[0]\n",
    "  cls = []\n",
    "\n",
    "  for x in bert_embeddings:\n",
    "    cls.append(x[0])\n",
    "  cls = torch.stack(cls)\n",
    "\n",
    "  preds = neigh.predict(cls)\n",
    "  return preds\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8c39b4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getGradeAndScore(preds):\n",
    "  good = 0\n",
    "  bad = 0\n",
    "  neutral = 0\n",
    "  blocker = 0\n",
    "\n",
    "  for c in preds :\n",
    "    if c == 0:\n",
    "      good +=1\n",
    "  \n",
    "    elif c == 1:\n",
    "      neutral +=1\n",
    "  \n",
    "    elif c == 2:\n",
    "      bad +=1\n",
    "  \n",
    "    elif c == 3:\n",
    "      blocker +=1\n",
    "\n",
    "  score = good - bad - 3*blocker\n",
    "\n",
    "  grade = \"\"\n",
    "  if score < -10:\n",
    "    grade = \"E\"\n",
    "\n",
    "  elif score > -10 and blocker > 0 :\n",
    "    grade = \"D\"\n",
    "\n",
    "  elif score > -10 and score < -4 and blocker ==0 :\n",
    "    grade = \"C\"\n",
    "\n",
    "  elif score > -4 and blocker == 0 and bad > 0 :\n",
    "    grade = \"B\"\n",
    "\n",
    "  else :\n",
    "    grade = \"A\"\n",
    "\n",
    "  return (score,grade)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78bb703a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "  def __init__(self, incoming = None):\n",
    "    self.incoming = None\n",
    "  def predict(self,incoming):\n",
    "    self.incoming= incoming    \n",
    "    self.incoming = clean(self.incoming)    \n",
    "    test_list = listify(self.incoming)\n",
    "    preds = getPreds(test_list)    \n",
    "    return getGradeAndScore(preds)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "6d62af18",
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Your max_length is set to 40, but you input_length is only 11. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "C:\\Users\\laksh\\anaconda3\\lib\\site-packages\\torch\\_tensor.py:575: UserWarning: floor_divide is deprecated, and will be removed in a future version of pytorch. It currently rounds toward 0 (like the 'trunc' function NOT 'floor'). This results in incorrect rounding for negative values.\n",
      "To keep the current behavior, use torch.div(a, b, rounding_mode='trunc'), or for actual floor division, use torch.div(a, b, rounding_mode='floor'). (Triggered internally at  ..\\aten\\src\\ATen\\native\\BinaryOps.cpp:467.)\n",
      "  return torch.floor_divide(self, other)\n",
      "Your max_length is set to 40, but you input_length is only 11. You might consider decreasing max_length manually, e.g. summarizer('...', max_length=50)\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0, 'B')"
      ]
     },
     "metadata": {},
     "execution_count": 12
    }
   ],
   "source": [
    "model_1 =  Model()\n",
    "model_1.predict(['<p>we sell you personal data without your permission','we can remove your account without your approval'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "799f0769",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "mod = pickle.load(open('modelnew.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95b14d4b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.8 64-bit ('base': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "interpreter": {
   "hash": "abe6ea5596d96cb069a4a04cd300d0d752935a8611d77134530a518bef7ebd90"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}